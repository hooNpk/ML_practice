----------------------------------------------------------------------------------------

실습자료 14장 readme.txt 개요

> 기본적인 오토인코더 모형 구현 (14장_기본적인 Autoencoder.ipynb)
> 심층 오토인코더 모형 구현 (14장_Deep Autoencoder (stacked AE).ipynb)
> CNN 기반의 컨볼루션 오토인코더 모형 구현 (14장_Convolutional Autoencoder.ipynb)
> 노이즈를 제거하는 디노이징 오토인코더 모형 구현 (14장_Denoising Autoencoder.ipynb)

---------------------------------------------------------------------------------------



<기본적인 오토인코더 모형 구현>


입력변수로부터 재구성(reconstruction)하는 과정을 통해 특성을 추출하는데 활용되는 오토인코더를 구현 및 학습한다.

이번 실습코드는 다음과 같은 과정으로 진행된다.
해당 과정은 14장의 모든 코드에서 동일하다. (순서는 조금씩 다를 수 있다.)

- 케라스 데이터셋으로부터 mnist 데이터 로드
- 인코더 및 디코더로 이루어진 오토인코더 모형 생성
- 생성된 오토인코더와 같은 인풋 차원을 가지도록 mnist의 x값 reshape (오토인코더에서 y값은 사용하지 않으므로 논외한다.)
- 오토인코더 모형 학습
- Loss 값 결과 출력 및 재구성 결과 시각화

오토인코더 모형을 학습하는데 사용되는 opimizer를 다양하게 실험해볼 수 있으며, fit() 함수의 hyperparameter인 batch_size와 epochs를 조절하여 학습을 조절하고, loss 값 결과를 토대로 적절한 hyperparameter를 찾을 수 있다.




<심층 오토인코더 모형 구현>


기본적인 오토인코더와 동일하게 진행하되, 오토인코더 모형 생성 시 더 깊은 층으로 구성하면 된다.
각 층의 활성함수를 변경하거나 dropout을 추가하는 등의 모델 구조를 변경해볼 수 있다.

위와 마찬가지로, 학습 시 optimizer를 변경해볼 수 있으며, fit() 함수의 hyperparameter인 batch_size와 epochs를 조절하여 학습을 조절해본다.




<CNN 기반의 컨볼루션 오토인코더 모형 구현>


컨볼루션 오토인코더는 심층 오토인코더가 MLP가 아닌 CNN으로 구성된다고 보면 된다.
따라서 인풋이 이미지 형태로 들어간다. 

또한, 오토인코더 모형 생성 시 Dense 함수가 아닌 Conv2D 함수를 사용한다. 
이 때 필터의 갯수, 커널의 크기, 활성함수의 종류를 다양하게 조절해볼 수 있다. (padding은 'same'으로 지정해야 해당 컨볼루션 계층의 인풋과 아웃풋의 차원이 동일해진다.)


위와 마찬가지로, 학습 시 optimizer를 변경해볼 수 있으며, fit() 함수의 hyperparameter인 batch_size와 epochs를 조절하여 학습을 조절해본다.




<노이즈를 제거하는 디노이징 오토인코더 모형 구현>


디노이징 오토인코더를 구현하기 위하여 mnist 데이터에 가우스 노이즈를 부여한다.
노이즈가 포함된 데이터 생성 시 noise factor를 변경하면 다양한 노이즈 데이터를 만들 수 있다.

이렇게 만들어진 노이즈 데이터를 먼저 시각화해본 후, 오토인코더를 이용하여 해당 데이터에 대한 재구성 과정을 거친다.
이번 실습에서는 컨볼루션 오토인코더를 이용했으나, 심층 오토인코더를 이용해볼 수 있다.

컨볼루션 오토인코더의 모형 생성 시 필터의 갯수, 커널의 크기, 활성함수의 종류를 다양하게 조절해볼 수 있다.
또한, 학습 시 optimizer를 변경해볼 수 있으며, fit() 함수의 hyperparameter인 batch_size와 epochs를 조절하여 학습을 조절해본다.

마지막으로, 재구성된 데이터의 시각화를 통해 오토인코더의 디노이징 효과를 확인한다.